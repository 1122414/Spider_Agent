import os
import json
import csv
import pandas as pd
import psycopg2
from psycopg2.extras import Json
from datetime import datetime
from typing import List, Dict, Any, Union

# å¼•å…¥ registry ä»¥è·å–ç¼“å­˜æ•°æ®
from agent.tools.registry import tool_registry

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
OUTPUT_DIR = "output"
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)

def _get_timestamp_filename(prefix: str, extension: str) -> str:
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    clean_prefix = "".join([c if c.isalnum() else "_" for c in prefix])
    return os.path.join(OUTPUT_DIR, f"{clean_prefix}_{timestamp}.{extension}")

def _extract_items(data: Any) -> List[Dict]:
    """è¾…åŠ©å‡½æ•°ï¼šç»Ÿä¸€ä» dict/list ä¸­æå– items åˆ—è¡¨"""
    if isinstance(data, dict):
        return data.get("data") or data.get("items") or data.get("target_content") or []
    if isinstance(data, list):
        return data
    return []

def _resolve_data(data: Union[Dict, List, None]) -> Union[Dict, List, None]:
    """
    ã€æ ¸å¿ƒä¿®å¤ã€‘æ™ºèƒ½æ•°æ®è§£æé€»è¾‘
    ä¸å†æ— è„‘ä¼˜å…ˆç¼“å­˜ï¼Œè€Œæ˜¯åˆ¤æ–­ä¼ å…¥æ•°æ®çš„æœ‰æ•ˆæ€§ã€‚
    """
    cached_data = tool_registry.last_execution_result
    
    # 1. å¦‚æœæ²¡ä¼  dataï¼Œå¿…é¡»ç”¨ç¼“å­˜
    if not data:
        if cached_data:
             print("ğŸ” [SaveTool] æœªä¼ å…¥ dataï¼Œè‡ªåŠ¨ä½¿ç”¨å†…å­˜ç¼“å­˜ã€‚")
             return cached_data
        return None

    # 2. å¦‚æœä¼ äº† dataï¼Œä¸”æœ‰ç¼“å­˜ï¼Œè¿›è¡Œæ™ºèƒ½æ¯”å¯¹
    if cached_data:
        # å¦‚æœç¼“å­˜æ˜¯é”™è¯¯ä¿¡æ¯ï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼Œç›´æ¥å¿½ç•¥ç¼“å­˜ï¼Œä½¿ç”¨ data
        if isinstance(cached_data, str):
             return data

        items_passed = _extract_items(data)
        items_cached = _extract_items(cached_data)
        
        # ã€åˆ¤å®šé€»è¾‘ã€‘ä»€ä¹ˆæ—¶å€™è¯¥ç”¨ç¼“å­˜è¦†ç›–ä¼ å…¥çš„æ•°æ®ï¼Ÿ
        # åªæœ‰å½“ï¼šä¼ å…¥æ•°æ®é‡æå°‘ï¼ˆ<5ï¼‰ AND ç¼“å­˜æ•°æ®é‡å¤§ï¼ˆ>5ï¼‰ AND çœ‹èµ·æ¥åƒæ˜¯ç¼“å­˜çš„å­é›†ï¼ˆæˆªæ–­ï¼‰
        if items_passed and items_cached:
            if len(items_passed) <= 5 and len(items_cached) > 5:
                # è¿›ä¸€æ­¥æ£€æŸ¥å†…å®¹æ˜¯å¦ç›¸ä¼¼ (æ¯”å¯¹ç¬¬ä¸€æ¡æ•°æ®)
                try:
                    # ç®€å•æ¯”å¯¹ç¬¬ä¸€æ¡æ•°æ®çš„åç§°æˆ–é“¾æ¥æ˜¯å¦ä¸€è‡´
                    first_passed = items_passed[0].get("é“¾æ¥") or items_passed[0].get("url") or items_passed[0].get("link")
                    first_cached = items_cached[0].get("é“¾æ¥") or items_cached[0].get("url") or items_cached[0].get("link")
                    
                    if first_passed and first_passed == first_cached:
                        print(f"ğŸ” [SaveTool] æ£€æµ‹åˆ°ä¼ å…¥æ•°æ® ({len(items_passed)}æ¡) å¯èƒ½æ˜¯ç¼“å­˜ ({len(items_cached)}æ¡) çš„æˆªæ–­ç‰ˆæœ¬ï¼Œè‡ªåŠ¨åˆ‡æ¢ä¸ºå®Œæ•´ç¼“å­˜ã€‚")
                        return cached_data
                except:
                    pass

        # å…¶ä»–æƒ…å†µï¼ˆä¾‹å¦‚ä¼ å…¥æ•°æ®æœ‰ children è€Œç¼“å­˜æ²¡æœ‰ï¼Œæˆ–è€…æ•°æ®å®Œå…¨ä¸åŒï¼‰ï¼Œå°Šé‡ä¼ å…¥çš„ data
        print(f"ğŸ” [SaveTool] å°Šé‡ä¼ å…¥çš„ data å‚æ•° (Items: {len(items_passed)})ï¼Œå¿½ç•¥ç¼“å­˜å†²çªã€‚")
        return data

    # 3. æ— ç¼“å­˜ï¼Œç›´æ¥ç”¨ data
    return data

def save_to_json(data: Dict[str, Any] = None, filename_prefix: str = "crawl_result") -> str:
    actual_data = _resolve_data(data)
    
    if not actual_data:
        return "ä¿å­˜å¤±è´¥: æ²¡æœ‰æ•°æ®å¯ä¿å­˜"

    file_path = _get_timestamp_filename(filename_prefix, "json")
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(actual_data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ JSON æ–‡ä»¶å·²ä¿å­˜: {file_path}")
        return f"æˆåŠŸä¿å­˜ JSON åˆ°: {file_path}"
    except Exception as e:
        return f"ä¿å­˜ JSON å¤±è´¥: {str(e)}"

def save_to_csv(data: Union[Dict, List] = None, filename_prefix: str = "crawl_result") -> str:
    actual_data = _resolve_data(data)
    
    if not actual_data:
        return "ä¿å­˜å¤±è´¥: æ²¡æœ‰æ•°æ®å¯ä¿å­˜"
    
    if isinstance(actual_data, str):
        return f"ä¿å­˜å¤±è´¥: æ•°æ®æ ¼å¼é”™è¯¯ (String): {actual_data[:50]}..."

    file_path = _get_timestamp_filename(filename_prefix, "csv")
    items = _extract_items(actual_data)
    
    # å¦‚æœ items ä¸ºç©ºä½† actual_data æœ¬èº«æ˜¯å•æ¡æ•°æ®
    if not items and isinstance(actual_data, dict) and "url" in actual_data:
        items = [actual_data]
        
    if not items:
        return f"ä¿å­˜ CSV å¤±è´¥: æ•°æ®ä¸­æœªæ‰¾åˆ°åˆ—è¡¨é¡¹ã€‚"

    try:
        df = pd.DataFrame(items)
        for col in df.columns:
            if df[col].dtype == 'object':
                df[col] = df[col].apply(lambda x: json.dumps(x, ensure_ascii=False) if isinstance(x, (list, dict)) else x)
        
        df.to_csv(file_path, index=False, encoding='utf-8-sig')
        print(f"ğŸ’¾ CSV æ–‡ä»¶å·²ä¿å­˜: {file_path} (å…± {len(df)} æ¡)")
        return f"æˆåŠŸä¿å­˜ CSV åˆ°: {file_path}"
    except Exception as e:
        return f"ä¿å­˜ CSV å¤±è´¥: {str(e)}"

def save_to_postgres(data: Union[Dict, List] = None, table_name: str = "crawled_data") -> str:
    actual_data = _resolve_data(data)
    if not actual_data or isinstance(actual_data, str):
        return "ä¿å­˜å¤±è´¥: æ²¡æœ‰æœ‰æ•ˆæ•°æ®"

    dsn = os.environ.get("POSTGRES_CONNECTION_STRING")
    if not dsn: return "ä¿å­˜å¤±è´¥: æœªè®¾ç½® POSTGRES_CONNECTION_STRING"

    items = _extract_items(actual_data)
    source_url = actual_data.get("root_url", "") if isinstance(actual_data, dict) else ""

    if not items: return "ä¿å­˜æ•°æ®åº“å¤±è´¥: æ•°æ®ä¸ºç©º"

    conn = None
    try:
        conn = psycopg2.connect(dsn)
        cur = conn.cursor()
        cur.execute(f"""
            CREATE TABLE IF NOT EXISTS {table_name} (
                id SERIAL PRIMARY KEY,
                source_url TEXT,
                crawled_at TIMESTAMP DEFAULT NOW(),
                content JSONB
            );
        """)
        for item in items:
            cur.execute(f"INSERT INTO {table_name} (source_url, content) VALUES (%s, %s)", (source_url, Json(item)))
        conn.commit()
        print(f"ğŸ’¾ å·²å°† {len(items)} æ¡æ•°æ®å­˜å…¥æ•°æ®åº“: {table_name}")
        return f"æˆåŠŸå°† {len(items)} æ¡æ•°æ®å­˜å…¥ DB"
    except Exception as e:
        if conn: conn.rollback()
        return f"æ•°æ®åº“æ“ä½œå¤±è´¥: {str(e)}"
    finally:
        if conn: conn.close()