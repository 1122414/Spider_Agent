import os
import time
import json
import uuid
import traceback
from typing import List, Dict, Any, Union
from dotenv import load_dotenv

# Milvus Native SDK
from pymilvus import (
    connections,
    utility,
    FieldSchema, 
    CollectionSchema, 
    DataType, 
    Collection,
    MilvusException
)

# LangChain Embeddings (ä»…ç”¨äºç”Ÿæˆç¨ å¯†å‘é‡)
from langchain_openai import OpenAIEmbeddings
from langchain_community.embeddings import OllamaEmbeddings

# å¼•å…¥ registry
from agent.tools.registry import tool_registry
from config import *

load_dotenv()

# ========================== é…ç½®åŒºåŸŸ ==========================
# å‘é‡ç»´åº¦éœ€ä¸ Embedding æ¨¡å‹ä¸€è‡´ (OpenAI text-embedding-3-small é»˜è®¤ä¸º 1536)
VECTOR_DIM = 4096
DENSE_FIELD_NAME = "dense_vector"
SPARSE_FIELD_NAME = "sparse_vector"

def get_embedding_model():
    """å·¥å‚å‡½æ•°ï¼šè‡ªåŠ¨é€‰æ‹© OpenAI æˆ– Ollama åµŒå…¥æ¨¡å‹"""
    if EMBEDDING_TYPE == 'local_ollama':
        print(f"ğŸ”Œ ä½¿ç”¨ OllamaEmbeddings (Model: {OPENAI_OLLAMA_EMBEDDING_MODEL})...")
        base_url = OPENAI_OLLAMA_BASE_URL.replace("/api/generate", "").replace("/v1", "").rstrip("/")
        return OllamaEmbeddings(base_url=base_url, model=OPENAI_OLLAMA_EMBEDDING_MODEL)
    elif EMBEDDING_TYPE == 'local_vllm':
        print(f"ğŸ”Œ ä½¿ç”¨ Vllm OpenAIEmbeddings (Model: {VLLM_OPENAI_EMBEDDING_MODEL})...")
        return OpenAIEmbeddings(
            model=VLLM_OPENAI_EMBEDDING_MODEL,
            openai_api_key=VLLM_OPENAI_EMBEDDING_API_KEY,
            openai_api_base=VLLM_OPENAI_EMBEDDING_BASE_URL,
            check_embedding_ctx_length=False
        )
    else:
        return OpenAIEmbeddings(
            model=EMBEDDING_MODEL,
            openai_api_key=OPENAI_API_KEY,
            openai_api_base=OPENAI_OLLAMA_BASE_URL
        )

# TODO: è¿™é‡Œéœ€è¦æ¥å…¥çœŸæ­£çš„ç¨€ç–å‘é‡æ¨¡å‹ (å¦‚ BGE-M3, SPLADE)
# ç›®å‰ä»…è¿”å›ä¼ªé€ æ•°æ®æˆ–ç©ºå­—å…¸ä»¥è·‘é€šæµç¨‹
def _get_sparse_vector(text: str) -> Dict[int, float]:
    """
    ç”Ÿæˆç¨€ç–å‘é‡ (Sparse Vector)ã€‚
    æ ¼å¼: {word_id: weight, ...} æˆ– Milvus æ¥å—çš„ç¨€ç–æ ¼å¼
    """
    # æ¨¡æ‹Ÿï¼šç®€å•çš„ Hash è¯é¢‘ (ä»…ç”¨äºæµ‹è¯• Pipelineï¼Œæ— å®é™…æ£€ç´¢æ„ä¹‰)
    # ç”Ÿäº§ç¯å¢ƒè¯·æ›¿æ¢ä¸º: splade_model.encode(text)
    sparse_vec = {}
    # ç®€å•çš„ä¼ªé€ é€»è¾‘ï¼šå–éƒ¨åˆ†å­—ç¬¦çš„ hash ä½œä¸º ID
    for char in text[:50]: 
        token_id = abs(hash(char)) % 10000 
        sparse_vec[token_id] = sparse_vec.get(token_id, 0.0) + 0.1
    return sparse_vec

def _init_collection(collection_name: str, drop_old: bool = False) -> Collection:
    """åˆå§‹åŒ– Milvus Collection (Define Schema & Index)"""
    try:
        connections.connect(alias="default", uri=MILVUS_URI)
        print(f"ğŸ”Œ Connected to Milvus at {MILVUS_URI}")
    except Exception as e:
        print(f"âŒ Failed to connect to Milvus: {e}")
        raise e

    if utility.has_collection(collection_name) and drop_old:
        print(f"ğŸ—‘ï¸ Dropping existing collection: {collection_name}")
        utility.drop_collection(collection_name)

    if utility.has_collection(collection_name):
        print(f"âœ… Collection {collection_name} exists. Loading...")
        return Collection(collection_name)

    print(f"ğŸ†• Creating new collection: {collection_name}...")
    
    # --- 1. Define Schema ---
    fields = [
        # ä¸»é”® (Auto ID)
        FieldSchema(name="pk", dtype=DataType.INT64, is_primary=True, auto_id=True),
        # ç¨ å¯†å‘é‡ (Dense Vector) - ç”¨äºè¯­ä¹‰æ£€ç´¢
        FieldSchema(name=DENSE_FIELD_NAME, dtype=DataType.FLOAT_VECTOR, dim=VECTOR_DIM),
        # ç¨€ç–å‘é‡ (Sparse Vector) - ç”¨äºå…³é”®è¯/æ··åˆæ£€ç´¢ (Milvus 2.4+)
        FieldSchema(name=SPARSE_FIELD_NAME, dtype=DataType.SPARSE_FLOAT_VECTOR), 
        # å…ƒæ•°æ®å­—æ®µ
        FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=65535), # åŸå§‹å†…å®¹
        FieldSchema(name="source", dtype=DataType.VARCHAR, max_length=1024),
        FieldSchema(name="title", dtype=DataType.VARCHAR, max_length=1024),
        FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=256),
        FieldSchema(name="type", dtype=DataType.VARCHAR, max_length=64), # parent_info / child_detail
        FieldSchema(name="crawled_at", dtype=DataType.INT64) # Timestamp
    ]
    
    schema = CollectionSchema(fields, description="Spider Agent Knowledge Base (Hybrid Ready)")
    col = Collection(name=collection_name, schema=schema)

    # --- 2. Create Indexes (å…³é”®æ­¥éª¤) ---
    print("ğŸ”¨ Building Indexes...")
    
    # A. ç¨ å¯†å‘é‡ç´¢å¼• (HNSW)
    dense_index_params = {
        "metric_type": "IP", # Inner Product
        "index_type": "HNSW",
        "params": {"M": 16, "efConstruction": 200}
    }
    col.create_index(field_name=DENSE_FIELD_NAME, index_params=dense_index_params)
    
    # B. ç¨€ç–å‘é‡ç´¢å¼• (SPARSE_INVERTED_INDEX)
    sparse_index_params = {
        "metric_type": "IP",
        "index_type": "SPARSE_INVERTED_INDEX",
        "params": {"drop_ratio_build": 0.2} # è¿‡æ»¤æ‰æƒé‡è¿‡å°çš„é¡¹ï¼Œå‡å°ç´¢å¼•ä½“ç§¯
    }
    col.create_index(field_name=SPARSE_FIELD_NAME, index_params=sparse_index_params)

    # C. æ ‡é‡å­—æ®µç´¢å¼• (åŠ é€Ÿ Metadata Filter)
    try:
        col.create_index(field_name="category", index_name="idx_category")
        col.create_index(field_name="type", index_name="idx_type")
    except Exception as e:
        print(f"   (Scalar index warning: {e})")

    print("âœ… Collection initialized successfully.")
    return col

def _resolve_data(data: Union[Dict, List, None]) -> Union[Dict, List, None]:
    cached_data = tool_registry.last_execution_result
    if cached_data:
        if isinstance(cached_data, str):
            print(f"âš ï¸ [SaveToKB] ç¼“å­˜æ•°æ®æ˜¯å­—ç¬¦ä¸²ï¼Œè·³è¿‡ã€‚")
        elif isinstance(cached_data, list) and len(cached_data) == 0:
            print("âš ï¸ [SaveToKB] ç¼“å­˜æ•°æ®ä¸ºç©ºã€‚")
            return cached_data
        else:
            print(f"ğŸ” [SaveToKB] ä½¿ç”¨å†…å­˜ç¼“å­˜æ•°æ®ã€‚")
            return cached_data
    return data if data else None

def _flatten_data_to_payloads(data: Union[List, Dict], category: str) -> List[Dict]:
    """
    å°†åµŒå¥—æ•°æ®æ‰å¹³åŒ–ä¸ºé€‚åˆæ’å…¥ Milvus çš„å­—å…¸åˆ—è¡¨
    """
    items = []
    if isinstance(data, list): items = data
    elif isinstance(data, dict):
        if "items" in data and isinstance(data["items"], list): items = data["items"]
        else: items = [data]
    
    if not items: return []

    payloads = []
    timestamp = int(time.time())

    for item in items:
        if not isinstance(item, dict): continue
        
        # æå–åŸºç¡€ä¿¡æ¯
        url = item.get("url") or item.get("link") or ""
        title = item.get("title") or "æœªå‘½åæ¡ç›®"
        
        # 1. æ„å»º Parent Text
        content_parts = []
        for k, v in item.items():
            if k in ["children", "target_content", "items"] or v is None: continue
            val_str = str(v).strip()
            if val_str: content_parts.append(f"{k}: {val_str}")
        
        parent_text = "\n".join(content_parts)
        if len(parent_text) > 5:
            payloads.append({
                "text": parent_text,
                "source": url,
                "title": title,
                "category": category,
                "type": "parent_info",
                "crawled_at": timestamp
            })

        # 2. æ„å»º Children Text
        children = item.get("children", [])
        if isinstance(children, list):
            for child in children:
                if not isinstance(child, dict): continue
                child_parts = []
                for k, v in child.items():
                    val_str = str(v).strip()
                    if val_str: child_parts.append(f"{k}: {val_str}")
                
                if child_parts:
                    child_text = f"ã€Š{title}ã€‹è¯¦æƒ…:\n" + "\n".join(child_parts)
                    payloads.append({
                        "text": child_text,
                        "source": url,
                        "title": title,
                        "category": category,
                        "type": "child_detail",
                        "crawled_at": timestamp
                    })
    return payloads

def save_to_milvus(data: Union[Dict, List] = None, category: str = "general") -> str:
    """
    å°†æ•°æ®å­˜å…¥ Milvus (Hybrid Ready)
    """
    actual_data = _resolve_data(data)
    if not actual_data: return "ä¿å­˜å¤±è´¥: æ²¡æœ‰æœ‰æ•ˆæ•°æ®"

    # 1. æ•°æ®æ¸…æ´—ä¸æ‰å¹³åŒ–
    payloads = _flatten_data_to_payloads(actual_data, category)
    if not payloads: return "ä¿å­˜å¤±è´¥: æ•°æ®è§£æåä¸ºç©º"
    
    print(f"ğŸ”„ å‡†å¤‡å…¥åº“ {len(payloads)} æ¡æ•°æ® (Category: {category})...")

    try:
        # 2. åˆå§‹åŒ– Collection (Drop Old=False é»˜è®¤ä¿ç•™æ•°æ®)
        col = _init_collection(COLLECTION_NAME, drop_old=False) 

        # 3. è®¡ç®—å‘é‡ (Dense Embedding)
        embeddings_model = get_embedding_model()
        texts = [p["text"] for p in payloads]
        
        print(f"âš¡ è®¡ç®— Dense Vectors (Batch: {len(texts)})...")
        dense_vectors = embeddings_model.embed_documents(texts)
        
        # 4. è®¡ç®—ç¨€ç–å‘é‡ (Sparse Embedding)
        print(f"âš¡ è®¡ç®— Sparse Vectors (Mock)...")
        sparse_vectors = [_get_sparse_vector(t) for t in texts]
        
        if len(dense_vectors) != len(payloads):
            return "ä¿å­˜å¤±è´¥: å‘é‡æ•°é‡ä¸æ–‡æœ¬æ•°é‡ä¸åŒ¹é…"

        # 5. ç»„è£… Insert Data (Column-based for PyMilvus)
        # é¡ºåºå¿…é¡»ä¸¥æ ¼å¯¹åº” Schema å®šä¹‰: 
        # [dense_vector, sparse_vector, text, source, title, category, type, crawled_at]
        entities = [
            dense_vectors,                              # dense_vector
            sparse_vectors,                             # sparse_vector
            [p["text"][:60000] for p in payloads],      # text
            [str(p["source"])[:1000] for p in payloads],# source
            [str(p["title"])[:1000] for p in payloads], # title
            [str(p["category"]) for p in payloads],     # category
            [p["type"] for p in payloads],              # type
            [p["crawled_at"] for p in payloads]         # crawled_at
        ]

        # 6. æ‰§è¡Œæ’å…¥
        print("ğŸ’¾ æ­£åœ¨å†™å…¥ Milvus...")
        insert_res = col.insert(entities)
        
        # 7. Flush (ç¡®ä¿æ•°æ®å¯è§)
        col.flush() 
        
        cnt = insert_res.insert_count
        return f"âœ… æˆåŠŸå…¥åº“ {cnt} æ¡æ•°æ® (Collection: {COLLECTION_NAME})"

    except Exception as e:
        traceback.print_exc()
        return f"âŒ å‘é‡æ•°æ®åº“æ“ä½œå¤±è´¥: {str(e)}"