import os
import time
import json
from typing import List, Dict, Any, Union
from dotenv import load_dotenv

# LangChain & Milvus
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings
from langchain_milvus import Milvus

# å¼•å…¥ registry ä»¥è·å–ç¼“å­˜æ•°æ®
from agent.tools.registry import tool_registry

load_dotenv()

# é…ç½®
MILVUS_URI = os.environ.get("MILVUS_URI", "http://localhost:19530")
COLLECTION_NAME = "spider_knowledge_base"
EMBEDDING_MODEL = os.environ.get("MODA_EMBEDDING_MODEL", "text-embedding-3-small")
OPENAI_API_KEY = os.environ.get("MODA_OPENAI_API_KEY")
OPENAI_BASE_URL = os.environ.get("MODA_OPENAI_BASE_URL")

def _resolve_data(data: Union[Dict, List, None]) -> Union[Dict, List, None]:
    """è§£ææ•°æ®ï¼Œä¼˜å…ˆä½¿ç”¨ç¼“å­˜"""
    cached_data = tool_registry.last_execution_result
    if cached_data:
        if isinstance(cached_data, str):
            print(f"âš ï¸ [SaveToKB] ç¼“å­˜æ•°æ®æ˜¯å­—ç¬¦ä¸²ï¼Œè·³è¿‡ã€‚")
        elif isinstance(cached_data, list) and len(cached_data) == 0:
            print("âš ï¸ [SaveToKB] ç¼“å­˜æ•°æ®ä¸ºç©ºã€‚")
            return cached_data
        else:
            print(f"ğŸ” [SaveToKB] ä½¿ç”¨å†…å­˜ç¼“å­˜æ•°æ®ã€‚")
            return cached_data
    return data if data else None

def _flatten_data_to_documents(data: Union[List, Dict]) -> List[Document]:
    """å°†æ ‘çŠ¶ç»“æ„çš„çˆ¬è™«æ•°æ®æ‰å¹³åŒ–ä¸º Document å¯¹è±¡åˆ—è¡¨"""
    items = []
    if isinstance(data, dict):
        items = data.get("data") or data.get("items") or data.get("target_content") or []
        if not items and "url" in data: items = [data]
    elif isinstance(data, list):
        items = data
        
    if not items: return []

    documents = []
    for item in items:
        if not isinstance(item, dict): continue
        
        title = item.get("ç”µå½±åç§°") or item.get("title") or item.get("name") or "æœªçŸ¥æ ‡é¢˜"
        url = item.get("é“¾æ¥") or item.get("url") or item.get("link") or ""
        
        # æ„å»ºçˆ¶çº§æ–‡æœ¬
        content_parts = []
        for k, v in item.items():
            if k not in ["children", "url", "link", "href", "è·³è½¬é“¾æ¥"] and v and isinstance(v, str) and v.strip():
                content_parts.append(f"{k}: {v.strip()}")
        
        parent_text = "\n".join(content_parts)
        
        if parent_text and len(parent_text.strip()) > 5:
            doc = Document(
                page_content=parent_text,
                metadata={"source": url, "title": title, "type": "parent_info"}
            )
            documents.append(doc)
            
        # å¤„ç† Children
        children = item.get("children", [])
        if isinstance(children, list):
            for child in children:
                if not isinstance(child, dict): continue
                child_parts = []
                for k, v in child.items():
                    if v and isinstance(v, str) and v.strip():
                        child_parts.append(f"{k}: {v.strip()}")
                
                if child_parts:
                    child_text = f"ã€Š{title}ã€‹çš„è¯¦ç»†ä¿¡æ¯:\n" + "\n".join(child_parts)
                    if child_text and len(child_text.strip()) > 5:
                        child_doc = Document(
                            page_content=child_text,
                            metadata={"source": url, "title": title, "type": "child_detail"}
                        )
                        documents.append(child_doc)
    return documents

def save_to_milvus(data: Union[Dict, List] = None) -> str:
    """
    å°†æ•°æ®å­˜å…¥ Milvus å‘é‡çŸ¥è¯†åº“ (ç¨³å¥ç‰ˆ)
    """
    actual_data = _resolve_data(data)
    if not actual_data:
        return "ä¿å­˜å¤±è´¥: æ²¡æœ‰æœ‰æ•ˆæ•°æ®"

    docs = _flatten_data_to_documents(actual_data)
    valid_docs = [d for d in docs if d.page_content and d.page_content.strip()]
    
    if not valid_docs:
        return "ä¿å­˜å¤±è´¥: æ•°æ®è½¬æ¢åä¸ºç©º"
    
    print(f"ğŸ”„ å‡†å¤‡å¤„ç† {len(valid_docs)} æ¡æ•°æ®ç‰‡æ®µ...")

    try:
        # 1. åˆå§‹åŒ– Embedding æ¨¡å‹
        embeddings = OpenAIEmbeddings(
            model=EMBEDDING_MODEL,
            openai_api_key=OPENAI_API_KEY,
            openai_api_base=OPENAI_BASE_URL
        )

        # 2. ã€æ‰‹åŠ¨è®¡ç®—å‘é‡ã€‘
        # ç»•è¿‡ LangChain çš„æ‰¹é‡å¤„ç† Bugï¼Œå¹¶å¢åŠ é€Ÿç‡é™åˆ¶é˜²æ­¢ 429
        text_embeddings = []
        metadatas = []
        texts = []
        
        print(f"âš¡ å¼€å§‹è®¡ç®—å‘é‡ (Manual Embedding Mode)...")
        for i, doc in enumerate(valid_docs):
            try:
                # æ¯æ¬¡åªç®—ä¸€æ¡ï¼Œæœ€ç¨³å¥
                # replace newlines æ˜¯å®˜æ–¹æ¨èåšæ³•
                clean_text = doc.page_content.replace("\n", " ")
                vector = embeddings.embed_query(clean_text)
                
                texts.append(doc.page_content)
                metadatas.append(doc.metadata)
                text_embeddings.append(vector)
                
                # ç®€å•çš„è¿›åº¦æ¡
                if (i + 1) % 5 == 0:
                    print(f"   -> å·²å‘é‡åŒ– {i + 1}/{len(valid_docs)} æ¡")
                
                # ã€å…³é”®ã€‘é˜² 429 é™æµï¼šæ¯æ¡é—´éš” 0.2 ç§’
                time.sleep(0.2)
                
            except Exception as e:
                print(f"   âš ï¸ ç¬¬ {i} æ¡åµŒå…¥å¤±è´¥: {e}")
                continue

        if not text_embeddings:
            return "ä¿å­˜å¤±è´¥: æ‰€æœ‰æ•°æ®å‘é‡åŒ–å‡å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API Key æˆ–ç½‘ç»œã€‚"

        print(f"âœ… å‘é‡è®¡ç®—å®Œæˆï¼Œå‡†å¤‡å­˜å…¥ Milvus ({len(text_embeddings)} æ¡)...")

        # 3. å­˜å…¥ Milvus
        # drop_old=True: å¼ºåˆ¶åˆ é™¤æ—§è¡¨ï¼Œè§£å†³ç»´åº¦å†²çª (4096 vs 1536)
        vector_store = Milvus(
            embedding_function=embeddings,
            connection_args={"uri": MILVUS_URI},
            collection_name=COLLECTION_NAME,
            auto_id=True,
            drop_old=True  # ã€å…³é”®ã€‘å¼ºåˆ¶é‡å»ºè¡¨
        )
        
        # ä½¿ç”¨ add_embeddings ç›´æ¥å­˜å…¥ç®—å¥½çš„å‘é‡ï¼Œä¸å†è®© LangChain é‡æ–°ç®—
        vector_store.add_embeddings(
            texts=texts,
            embeddings=text_embeddings,
            metadatas=metadatas
        )
        
        print(f"ğŸ’¾ å…¨éƒ¨å®Œæˆï¼æˆåŠŸå­˜å…¥ Milvusã€‚")
        return f"æˆåŠŸå°† {len(text_embeddings)} æ¡æ•°æ®å­˜å…¥çŸ¥è¯†åº“ (Collection: {COLLECTION_NAME}, Recreated)"
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return f"å‘é‡æ•°æ®åº“æ“ä½œå¤±è´¥: {str(e)}"